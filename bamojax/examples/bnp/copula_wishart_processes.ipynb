{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copula Wishart processes\n",
    "\n",
    "Wishart processes are used to model input-dependent covariance matrices. They can naturally be combined with multivariate Gaussian observations, as the Wishart process then simply provides the covariance matrix for the Gaussian at every input point. However, the situation becomes less straightforward when the observations are not Gaussian, or not even continuous. Here, we explore copula models that allow us to separate the multivariate correlation structure from the desired marginal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA visible devices to [4]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "SELECTED_DEVICE = '4'\n",
    "print(f'Setting CUDA visible devices to [{SELECTED_DEVICE}]')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = f'{SELECTED_DEVICE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:        3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]\n",
      "Jax version:           0.4.35\n",
      "BlackJax version:      1.2.4\n",
      "Distrax version:       0.1.5\n",
      "Jax default backend:   gpu\n",
      "Jax devices:           [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.random as jrnd\n",
    "import jax.numpy as jnp\n",
    "import distrax as dx\n",
    "import blackjax\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from blackjax import normal_random_walk\n",
    "from blackjax.diagnostics import potential_scale_reduction, effective_sample_size\n",
    "\n",
    "from jaxtyping import Array\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../')))\n",
    "\n",
    "from bamojax.base import Node, Model\n",
    "from bamojax.sampling import gibbs_sampler, smc_inference_loop, elliptical_slice_nd, inference_loop\n",
    "\n",
    "from bamojax.more_distributions import GaussianProcessFactory, RBF, Zero, Wishart\n",
    "\n",
    "print('Python version:       ', sys.version)\n",
    "print('Jax version:          ', jax.__version__)\n",
    "print('BlackJax version:     ', blackjax.__version__)\n",
    "print('Distrax version:      ', dx.__version__)\n",
    "print('Jax default backend:  ', jax.default_backend())\n",
    "print('Jax devices:          ', jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copulas\n",
    "\n",
    "But first, estimate a covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2tril(v):\n",
    "    L_sample = jnp.zeros((p, p))\n",
    "    return L_sample.at[jnp.tril_indices(p, 0)].set(v)\n",
    "\n",
    "#\n",
    "\n",
    "def posdef_sigma(loc, L_vec):\n",
    "    L = vec2tril(L_vec)\n",
    "    return dict(loc=loc, covariance_matrix=jnp.dot(L, L.T))\n",
    "\n",
    "#\n",
    "cov = jnp.array([[1.0, 0.2], [0.2, 1.0]])\n",
    "p = cov.shape[0]\n",
    "nu = p + 1\n",
    "n = 1000\n",
    "m = int(p*(p+1)/2)\n",
    "\n",
    "key = jrnd.PRNGKey(42)\n",
    "key, subkey = jrnd.split(key)\n",
    "\n",
    "Y = jrnd.multivariate_normal(subkey, mean=jnp.zeros(p), cov=cov, shape=(n, ))\n",
    "\n",
    "copula_model = Model('Copulas')\n",
    "L_node = copula_model.add_node(name='L_vec', distribution=dx.Normal(loc=jnp.zeros(m), scale=jnp.ones(m)))\n",
    "Y_node = copula_model.add_node(name='Y', distribution=dx.MultivariateNormalFullCovariance, parents=dict(loc=jnp.zeros(p), L_vec=L_node), observations=Y, link_fn=posdef_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Naive proposals do not impose a positive definiteness constraint on $\\Sigma$ - we should instead sample $L$ in $\\Sigma=LL^\\top$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 0.359\n",
      "CPU times: user 15.1 s, sys: 914 ms, total: 16 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logdensity_fn = lambda state: copula_model.loglikelihood_fn()(state) + copula_model.logprior_fn()(state)\n",
    "rmh = normal_random_walk(logdensity_fn, sigma=0.03*jnp.eye(m))\n",
    "\n",
    "num_samples = 50_000\n",
    "num_burn = 50_000\n",
    "num_thin = 1\n",
    "num_chains = 1\n",
    "\n",
    "rmh_states, rmh_info = inference_loop(key, model=copula_model, kernel=rmh, num_samples=num_samples, num_burn=num_burn, num_chains=num_chains, num_thin=num_thin)\n",
    "\n",
    "print(f'Acceptance rate: {jnp.mean(1.0*rmh_info.is_accepted):0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.99330278, 0.21618209],\n",
       "       [0.21618209, 0.97584776]], dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn_params = jax.vmap(posdef_sigma, in_axes=(None, 0))(jnp.zeros(p), rmh_states.position['L_vec'])\n",
    "\n",
    "jnp.mean(mvn_params['covariance_matrix'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian-Poisson copulas\n",
    "\n",
    "Try and implement the following example: https://users.aalto.fi/~johnsoa2/notebooks/CopulaIntro.html#mixed-continuous-discrete-marginals\n",
    "\n",
    "Unfortunately, neither distrax, TFP, nor jax.scipy.stats implement the Poisson quantile functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.2]\n",
      " [0.2 1. ]]\n",
      "(2, 40)\n",
      "(2, 40)\n"
     ]
    }
   ],
   "source": [
    "def cov2corr(Sigma):\n",
    "    v = jnp.sqrt(jnp.diag(Sigma))\n",
    "    outer_v = jnp.outer(v, v)\n",
    "    correlation = Sigma / outer_v\n",
    "    return correlation\n",
    "\n",
    "#\n",
    "key, subkey = jrnd.split(key)\n",
    "\n",
    "\n",
    "P = cov2corr(cov)  # it was already scaled...\n",
    "print(P)\n",
    "n = 40\n",
    "\n",
    "L = jnp.linalg.cholesky(P)\n",
    "\n",
    "Z = jrnd.multivariate_normal(key=subkey, mean=jnp.zeros((p, )), cov=jnp.eye(p), shape=(n,)).T\n",
    "\n",
    "X = jnp.dot(L, Z)\n",
    "\n",
    "print(Z.shape)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R's dnorm, pnorm, qnorm, rnorm notation for density, cumulative density, quantile, random variate\n",
    "\n",
    "pnorm = lambda z: tfp.distributions.Normal(loc=0.0, scale=1.0).cdf(z)  #  P(Z <= z)\n",
    "qnorm = lambda z: tfp.distributions.Normal(loc=0.0, scale=1.0).quantile(z)  # P^{-1}(u), u \\in [0, 1]\n",
    "\n",
    "jax.scipy.stats.poisson.pdf(0.1)\n",
    "lamb = 30\n",
    "\n",
    "y_copula = pnorm(Z)\n",
    "\n",
    "Y = tfp.distributions.Poisson(rate=lamb).quantile(y_copula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian copula graphical models\n",
    "\n",
    "See Mohammadi et al. (2016):\n",
    "\n",
    "Introduce latent variables $Z$, s.t.:\n",
    "\n",
    "$$\n",
    "    Z \\sim \\mathcal{N}_p\\left(0, \\Sigma\\right) \\enspace.\n",
    "$$\n",
    "We instead observe mixed-type data \n",
    "$$\n",
    "    Y_j = F^{-1}_j\\left(\\Phi(z_j)\\right) \\enspace,\n",
    "$$ \n",
    "where $F_j$ is the marginal (cumulative?) distribution of variable $j$, $F^{-1}_j$ its inverse, and $\\Phi(\\cdot)$ the cumulative density of the standard univariate Gaussian distribution. \n",
    "\n",
    "The Gaussian copula-based joint cumulative distribution of the observations $Y$ is then given by\n",
    "$$\n",
    "    P(Y_1 \\leq y_1, \\ldots, Y_p \\leq y_p) = \\Phi_{\\Sigma} \\left[\\Phi^{-1}\\left(F_1(y_1)\\right), \\ldots, \\Phi^{-1}\\left(F_p(y_p)\\right) \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "gaussian_copula = lambda x: dx.Normal(loc=0.0, scale=1.0).cdf(x)\n",
    "\n",
    "U = jax.vmap(jax.vmap(gaussian_copula))(X)\n",
    "\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.70673703],\n",
       "       [0.17704843]], dtype=float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.Gamma(concentration=1.0, rate=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uicsdev_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
