{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a69cb1",
   "metadata": {},
   "source": [
    "# Truncated Harmonic Mean Estimator (THAMES)\n",
    "\n",
    "Metodiev et al. (2025), Bayesian Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854669b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA visible devices to [0]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "SELECTED_DEVICE = '0'\n",
    "print(f'Setting CUDA visible devices to [{SELECTED_DEVICE}]')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = f'{SELECTED_DEVICE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd68d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:      3.11.13 | packaged by conda-forge | (main, Jun  4 2025, 14:48:23) [GCC 13.3.0]\n",
      "Jax version:         0.7.2\n",
      "BlackJax version:    1.2.5\n",
      "Bamojax version:     0.3.10+4.gf6f1d99.dirty\n",
      "Numpyro version:     0.19.0\n",
      "Jax default backend: gpu\n",
      "Jax devices:         [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.random as jrnd\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import logsumexp, gammaln\n",
    "\n",
    "import blackjax\n",
    "import numpyro as npr\n",
    "import numpyro.distributions as dist\n",
    "import numpyro.distributions.transforms as nprb\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import bamojax\n",
    "from bamojax.base import Model\n",
    "from bamojax.samplers import mcmc_sampler\n",
    "from bamojax.inference import MCMCInference, SMCInference\n",
    "from bamojax.marginal_likelihoods.utility import flatten_dict_to_array\n",
    "from bamojax.marginal_likelihoods.bridge_sampling import bridge_sampling\n",
    "from bamojax.marginal_likelihoods.thames import thames\n",
    "\n",
    "print('Python version:     ', sys.version)\n",
    "print('Jax version:        ', jax.__version__)\n",
    "print('BlackJax version:   ', blackjax.__version__)\n",
    "print('Bamojax version:    ', bamojax.__version__)\n",
    "print('Numpyro version:    ', npr.__version__)\n",
    "print('Jax default backend:', jax.default_backend())\n",
    "print('Jax devices:        ', jax.devices())\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2351cf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = ['2005-06', '2006-07', '2007-08']\n",
    "goals = []\n",
    "\n",
    "for year in files:\n",
    "    df = pd.read_csv(f'/scratch/big/home/maxhin/Documents/Code/Bayesian Model Comparison/data/English premiership/{year}.csv')  \n",
    "    total_goals = df['FTHG'] + df['FTAG']\n",
    "    total_goals_array = total_goals.to_numpy()\n",
    "    goals.extend(total_goals_array)\n",
    "\n",
    "Y = jnp.array(goals)\n",
    "n = len(Y)\n",
    "plt.figure(figsize=(6, 3))\n",
    "ax = plt.gca()\n",
    "ax.hist(Y, bins=jnp.arange(0, 10, 1))\n",
    "ax.set_xlabel('Goals')\n",
    "ax.set_xlabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b63f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_negative_binomial_model(observations) -> Model:\n",
    "    # Note: Hastie & Green, Wikipedia, and TFD all have their own parametrizations of the negative binomial\n",
    "    def negbin_link_fn(rate, dispersion):\n",
    "        p = rate / (rate + 1 / dispersion)\n",
    "        r = 1 / dispersion\n",
    "        return dict(probs=p, total_count=r)\n",
    "\n",
    "    #\n",
    "\n",
    "    model = Model('Negative binomial')\n",
    "    rate_node = model.add_node('lam', distribution=dist.Gamma(concentration=25, rate=10)) \n",
    "    dispersion_node = model.add_node('kappa', distribution=dist.Gamma(concentration=1, rate=10))  \n",
    "    _ = model.add_node('Y', observations=observations, parents=dict(rate=rate_node, dispersion=dispersion_node), distribution=dist.NegativeBinomialProbs, link_fn=negbin_link_fn)\n",
    "    return model\n",
    "\n",
    "#\n",
    "\n",
    "model = construct_negative_binomial_model(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd3fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapting NUTS HMC parameters... done.\n",
      "CPU times: user 20.4 s, sys: 1.55 s, total: 21.9 s\n",
      "Wall time: 8.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 5_000\n",
    "key = jrnd.PRNGKey(0)\n",
    "key, subkey = jrnd.split(key)\n",
    "\n",
    "m = model.get_model_size()\n",
    "cold_nuts_parameters = dict(step_size=0.5, inverse_mass_matrix=0.0001*jnp.eye(m))  # these will be overriden by the window adaptation\n",
    "nuts_kernel = mcmc_sampler(model=model, mcmc_kernel=blackjax.nuts, mcmc_parameters=cold_nuts_parameters)\n",
    "\n",
    "# we want to sample twice as many samples, since we need them for constructing the bridge density as well as for...\n",
    "engine = MCMCInference(model=model, mcmc_kernel=nuts_kernel, num_samples=2*N, num_burn=0, num_warmup=1_000, num_thin=1)\n",
    "results = engine.run(subkey)\n",
    "\n",
    "posterior_samples = results['states']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e010173",
   "metadata": {},
   "source": [
    "Marginal likelihood should be somewhere around -2106.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15deb8",
   "metadata": {},
   "source": [
    "## THAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0786896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THAMES estimator: -2106.369620990967\n"
     ]
    }
   ],
   "source": [
    "lml_thames = thames(jrnd.PRNGKey(0), model, posterior_samples)\n",
    "\n",
    "print('THAMES estimator:', lml_thames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b5865",
   "metadata": {},
   "source": [
    "Compare with bridge sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e779e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridge sampling estimate: -2106.382331654749\n"
     ]
    }
   ],
   "source": [
    "bridge_bijectors = dict(lam=nprb.ExpTransform(), kappa=nprb.ExpTransform())\n",
    "\n",
    "\n",
    "lml_bs, _ = bridge_sampling(key=jrnd.PRNGKey(1),\n",
    "                            model=model,\n",
    "                            posterior_samples=posterior_samples, \n",
    "                            bijectors=bridge_bijectors, \n",
    "                            proposal_type='gaussian', N2=1000)\n",
    "\n",
    "print('Bridge sampling estimate:', lml_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede45226",
   "metadata": {},
   "source": [
    "## Eight schools data\n",
    "\n",
    "To verify the approach works with different parameter shapes, let's try the log marginal likelihood estimators on the eight schools model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3942e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMC log marginal likelihood: -36.13476016390077\n"
     ]
    }
   ],
   "source": [
    "means = jnp.array([28, 8, -3, 7, -1, 1, 18, 12])\n",
    "stddevs = jnp.array([15, 10, 16, 11, 9, 11, 10, 18])\n",
    "\n",
    "J = len(means)\n",
    "\n",
    "ES = Model('eight schools')\n",
    "mu = ES.add_node('mu', distribution=dist.Normal(loc=0, scale=10))\n",
    "tau = ES.add_node('tau', distribution=dist.TransformedDistribution(dist.Normal(loc=5, scale=1), nprb.ExpTransform()))\n",
    "theta = ES.add_node('theta', distribution=dist.Normal, parents=dict(loc=mu, scale=tau), shape=(J, ))\n",
    "y = ES.add_node('y', distribution=dist.Normal, parents=dict(loc=theta, scale=stddevs), observations=means)\n",
    "\n",
    "m = ES.get_model_size()\n",
    "mcmc_params = dict(sigma=4.0*jnp.eye(m))\n",
    "rmh_kernel = mcmc_sampler(ES, mcmc_kernel=blackjax.normal_random_walk, mcmc_parameters=mcmc_params)\n",
    "\n",
    "num_particles = 5_000\n",
    "num_mutations = 200\n",
    "num_chains = 1\n",
    "\n",
    "key = jrnd.PRNGKey(0)\n",
    "\n",
    "engine = SMCInference(model=ES, num_chains=num_chains, mcmc_kernel=rmh_kernel, num_particles=num_particles, num_mutations=num_mutations)\n",
    "result = engine.run(key)\n",
    "ES_SMC_posterior_samples = result['final_state'].particles\n",
    "\n",
    "print('SMC log marginal likelihood:', result['lml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee5e4985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapting NUTS HMC parameters... done.\n",
      "CPU times: user 5.88 s, sys: 268 ms, total: 6.14 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 5_000\n",
    "key = jrnd.PRNGKey(0)\n",
    "key, subkey = jrnd.split(key)\n",
    "\n",
    "m = ES.get_model_size()\n",
    "cold_nuts_parameters = dict(step_size=0.5, inverse_mass_matrix=0.0001*jnp.eye(m))  # these will be overriden by the window adaptation\n",
    "nuts_kernel = mcmc_sampler(model=ES, mcmc_kernel=blackjax.nuts, mcmc_parameters=cold_nuts_parameters)\n",
    "\n",
    "# we want to sample twice as many samples, since we need them for constructing the bridge density as well as for...\n",
    "engine = MCMCInference(model=ES, mcmc_kernel=nuts_kernel, num_samples=2*N, num_burn=0, num_warmup=1_000, num_thin=1)\n",
    "results = engine.run(subkey)\n",
    "\n",
    "ES_NUTS_posterior_samples = results['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior samples using SMC:\n",
      "THAMES estimator: -36.00558919799167\n",
      "Bridge sampling estimate: -36.157942830761996\n",
      "Posterior samples using NUTS:\n",
      "THAMES estimator: -35.98432733521786\n",
      "Bridge sampling estimate: -36.124341067462304\n"
     ]
    }
   ],
   "source": [
    "print('Posterior samples using SMC:')\n",
    "\n",
    "es_lml_thames = thames(jrnd.PRNGKey(1), model=ES, posterior_samples=ES_SMC_posterior_samples)\n",
    "\n",
    "print('THAMES estimator:', es_lml_thames)\n",
    "\n",
    "bridge_bijectors = dict(tau=nprb.ExpTransform())\n",
    "es_lml_bs, _ = bridge_sampling(key=jrnd.PRNGKey(1),\n",
    "                               model=ES,\n",
    "                               posterior_samples=ES_SMC_posterior_samples, \n",
    "                               bijectors=bridge_bijectors, \n",
    "                               proposal_type='gaussian', N2=1000)\n",
    "\n",
    "print('Bridge sampling estimate:', es_lml_bs)\n",
    "\n",
    "print('Posterior samples using NUTS:')\n",
    "\n",
    "es_lml_thames = thames(jrnd.PRNGKey(1), model=ES, posterior_samples=ES_NUTS_posterior_samples)\n",
    "\n",
    "print('THAMES estimator:', es_lml_thames)\n",
    "\n",
    "es_lml_bs, _ = bridge_sampling(key=jrnd.PRNGKey(1),\n",
    "                               model=ES,\n",
    "                               posterior_samples=ES_NUTS_posterior_samples, \n",
    "                               bijectors=bridge_bijectors, \n",
    "                               proposal_type='gaussian', N2=1000)\n",
    "\n",
    "print('Bridge sampling estimate:', es_lml_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10af99",
   "metadata": {},
   "source": [
    "## Expectancy-valence model\n",
    "\n",
    "Here, we compare the following log marginal likelihood estimators on the expectancy-valence model (see Steingroever et al., 2016; Gronau et al., 2017; Hinne, 2025 for more details):\n",
    "\n",
    "- Importance sampling (Steingroever et al. implementation)\n",
    "- Bridge sampling (Gronau et al. implementation)\n",
    "- Bridge sampling (bamojax implementation)\n",
    "- SMC (bamojax implementation)\n",
    "- THAMES (bamojax implementation)\n",
    "\n",
    "First, load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d87e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully!\n",
      "File downloaded successfully!\n",
      "File downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pyreadr as pr\n",
    "import requests\n",
    "\n",
    "def download_to_disk(url, filepath):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filepath, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print('File downloaded successfully!')\n",
    "    else:\n",
    "        print(f'Failed to download the file. Status code: {response.status_code}')\n",
    "\n",
    "#\n",
    "data_busemeyer_url = 'https://osf.io/download/5vws6/'  # DataBusemeyerNoNA.rdata on https://osf.io/f9cq4/; contains IGT data\n",
    "data_busemeyer_file = 'DataBusemeyerNoNA.rdata'\n",
    "\n",
    "data_steingroever_url = 'https://osf.io/download/bmnsv/'  # contains Steingroever's importance sampling marginal likelihoods\n",
    "data_steingroever_file = 'DataSteingroever.rdata'\n",
    "\n",
    "lml_url = 'https://osf.io/download/txnbs/' # ind_LogMargLik.txt on https://osf.io/f9cq4/; contains Gronau's bridge sampling estmates\n",
    "lml_file = 'ind_LogMargLik.txt'\n",
    "\n",
    "download_to_disk(data_busemeyer_url, data_busemeyer_file)\n",
    "download_to_disk(data_steingroever_url, data_steingroever_file)\n",
    "download_to_disk(lml_url, lml_file)\n",
    "\n",
    "data_file = pr.read_r('DataBusemeyerNoNA.rdata')\n",
    "choices = jnp.asarray(data_file['choice'].to_numpy().astype(int)) - 1  # Python zero-indexing\n",
    "losses = jnp.asarray(data_file['lo'].to_numpy())\n",
    "wins = jnp.asarray(data_file['wi'].to_numpy())\n",
    "\n",
    "N, T = choices.shape\n",
    "K = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab7432",
   "metadata": {},
   "source": [
    "Form bamojax model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339eaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_link_fn(w, a, c_raw, choices, wins, losses):\n",
    "    c = 4*c_raw - 2.0\n",
    "    ev = jnp.zeros((K, ))\n",
    "    logits = jnp.ones((T, K))  # softmax of uniform is = [1/K, 1/K, ...]\n",
    "\n",
    "    def for_body(t, carry):\n",
    "        ev_, logits_ = carry\n",
    "        theta = (0.1*(t+1))**c  \n",
    "        current_utility = (1-w) * wins[t] + w*losses[t]\n",
    "        k = choices[t]\n",
    "        ev_ = ev_.at[k].add(a * (current_utility - ev_[k]))\n",
    "        logits_ = logits_.at[t + 1, :].set(theta * ev_)\n",
    "        return (ev_, logits_)\n",
    "    \n",
    "    #\n",
    "    _, logits = jax.lax.fori_loop(0, T - 1, for_body, (ev, logits))\n",
    "\n",
    "    return dict(logits=logits)\n",
    "\n",
    "#\n",
    "def make_ev_model(subject):\n",
    "    EVModel = Model(f'Expectance valence model, subject {subject}')\n",
    "    w_node = EVModel.add_node('w', distribution=dist.Beta(concentration0=1.0, concentration1=1.0))\n",
    "    a_node = EVModel.add_node('a', distribution=dist.Beta(concentration0=1.0, concentration1=1.0))\n",
    "    c_raw_node = EVModel.add_node('c_raw', distribution=dist.Beta(concentration0=1.0, concentration1=1.0))\n",
    "    wins_node = EVModel.add_node('wins', observations=wins[subject, :])\n",
    "    loss_node = EVModel.add_node('losses', observations=losses[subject, :])\n",
    "\n",
    "    # Note that in RL examples we often have a form of autoregression. Here, `choices` are observed, but also feed back into the model.\n",
    "    choice_node = EVModel.add_node('choices', \n",
    "                                observations=choices[subject, :], \n",
    "                                distribution=dist.Categorical, \n",
    "                                link_fn=ev_link_fn, \n",
    "                                parents=dict(w=w_node, \n",
    "                                                a=a_node, \n",
    "                                                c_raw=c_raw_node, \n",
    "                                                choices=choices[subject,:], \n",
    "                                                wins=wins_node, \n",
    "                                                losses=loss_node))\n",
    "    return EVModel\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c14e80",
   "metadata": {},
   "source": [
    "Run inference for all subjects, here we use SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2395d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 9.51 s, total: 45.1 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def wrapper(key, subject):\n",
    "    evmodel = make_ev_model(subject=subject)\n",
    "    mcmc_params = dict(sigma=stepsize*jnp.eye(evmodel.get_model_size()))\n",
    "    mcmc = mcmc_sampler(evmodel, mcmc_kernel=blackjax.normal_random_walk, mcmc_parameters=mcmc_params)\n",
    "    engine = SMCInference(model=evmodel, mcmc_kernel=mcmc, num_particles=num_particles, num_mutations=num_mcmc_steps, num_chains=num_chains)\n",
    "    result = engine.run(key)\n",
    "    return result\n",
    "\n",
    "#\n",
    "num_chains = 1\n",
    "num_mcmc_steps = 100\n",
    "num_particles = 1000\n",
    "stepsize = 0.01\n",
    "\n",
    "subjects = jnp.arange(N)\n",
    "key = jrnd.PRNGKey(42)\n",
    "keys = jrnd.split(key, N)\n",
    "smc_fits = jax.vmap(wrapper)(keys, subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c9176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior samples using SMC:\n",
      "THAMES estimator: [-130.27733121 -104.76012925 -115.44883197 -117.90032783 -104.43759616\n",
      " -137.11821349 -137.5729163  -129.95182013 -141.84123378  -89.40115296\n",
      " -133.42440438 -141.11109241 -140.39347713 -133.05980557 -133.35433378\n",
      " -137.28686024 -136.13324586 -109.51661239 -106.59221755 -141.24126\n",
      " -140.59201871 -109.71502738 -118.92695418 -138.32917349 -131.29963943\n",
      " -122.18857286 -125.19819512 -140.99577242 -138.12338629 -128.24655851]\n"
     ]
    }
   ],
   "source": [
    "print('Posterior samples using SMC:')\n",
    "\n",
    "key = jrnd.PRNGKey(0)\n",
    "key, subkey = jrnd.split(key)\n",
    "smc_thames_keys = jrnd.split(key, N)\n",
    "\n",
    "def thames_wrapper(key, subject, posterior_samples):\n",
    "    evmodel = make_ev_model(subject=subject)\n",
    "    return thames(key, model=evmodel, posterior_samples=posterior_samples)\n",
    "\n",
    "#\n",
    "ev_lml_thames = jax.vmap(thames_wrapper)(smc_thames_keys, subjects, posterior_samples=smc_fits['final_state'].particles)\n",
    "print('THAMES estimator:', ev_lml_thames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b752ecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridge sampling estimate: [-130.14472543 -104.43969575 -115.45323894 -117.69982064 -104.70372345\n",
      " -136.63891618 -137.79991104 -129.61339227 -141.57564695  -89.79338383\n",
      " -133.2323416  -140.71952166 -140.41294612 -133.14633809 -133.11917962\n",
      " -137.11578666 -135.97142507 -110.10322304 -106.59074473 -141.41937743\n",
      " -140.83553261 -109.99595123 -118.96971725 -138.48292814 -131.48988755\n",
      " -122.18476594 -125.10045441 -140.78777045 -138.42227539 -128.65331827]\n"
     ]
    }
   ],
   "source": [
    "import numpyro.distributions.constraints as constraints\n",
    "from numpyro.distributions.transforms import Transform\n",
    "\n",
    "class ProbitTransform(Transform):\n",
    "\n",
    "    def __init__(self, domain=constraints.real):\n",
    "        self.domain = domain\n",
    "        self.codomain = constraints.unit_interval\n",
    "\n",
    "    #\n",
    "    def __call__(self, x):\n",
    "        # forward: R -> (0,1)\n",
    "        return 0.5 * (1.0 + jax.lax.erf(x / jnp.sqrt(2.0)))\n",
    "\n",
    "    #\n",
    "    def _inverse(self, y):\n",
    "        # inverse: (0,1) -> R  (clipped for numerical stability)\n",
    "        return jnp.sqrt(2.0) * jax.scipy.special.erfinv(2.0 * y - 1.0)\n",
    "\n",
    "    #\n",
    "    def log_abs_det_jacobian(self, x, y, intermediates=None):\n",
    "        # log |dΦ/dx| = log φ(x) = -0.5 x^2 - 0.5 log(2π)\n",
    "        return -0.5 * x**2 - 0.5 * jnp.log(2.0 * jnp.pi)\n",
    "\n",
    "    #\n",
    "    def tree_flatten(self):\n",
    "        return (self.domain,), ((\"domain\",), dict())\n",
    "    \n",
    "    #\n",
    "\n",
    "#\n",
    "bridge_bijectors = dict(w=ProbitTransform(), a=ProbitTransform(), c_raw=ProbitTransform())\n",
    "\n",
    "def bridge_wrapper(key, subject, posterior_samples):\n",
    "    evmodel = make_ev_model(subject=subject)\n",
    "    lml_bs, _ = bridge_sampling(key=key,\n",
    "                                model=evmodel,\n",
    "                                posterior_samples=posterior_samples,\n",
    "                                bijectors=bridge_bijectors,\n",
    "                                proposal_type='gaussian', N2=1000)\n",
    "    return lml_bs\n",
    "\n",
    "key, subkey = jrnd.split(key)\n",
    "key_bridge = jrnd.split(subkey, N)\n",
    "\n",
    "ev_lml_bs_bamojax = jax.vmap(bridge_wrapper)(key_bridge, subjects, posterior_samples=smc_fits['final_state'].particles)\n",
    "\n",
    "print('Bridge sampling estimate:', ev_lml_bs_bamojax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix between methods:\n",
      "[[1.         0.99999883 0.99995063 0.99997861 0.99981959]\n",
      " [0.99999883 1.         0.99995314 0.99998266 0.99981235]\n",
      " [0.99995063 0.99995314 1.         0.9999612  0.99984013]\n",
      " [0.99997861 0.99998266 0.9999612  1.         0.99980012]\n",
      " [0.99981959 0.99981235 0.99984013 0.99980012 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# importance sampling results from Steingroever et al. (2016)\n",
    "is_lmls_file = pr.read_r(os.path.join(Path(os.getcwd()).parents[0], 'cognitive_models/DataSteingroever.rdata'))\n",
    "is_lmls = jnp.squeeze(jnp.log(pr.read_r(f'/scratch/big/home/maxhin/Documents/Code/SMC tutorial/EV/data/margLike_SteingroeverEtAl2016_importance_sampling.Rdata')['marg.like'].to_numpy()))\n",
    "\n",
    "# bridge sampling results from Gronau et al. (2017)\n",
    "bs_lmls_file = open(f'ind_LogMargLik.txt')\n",
    "lines = bs_lmls_file.readlines()\n",
    "bs_lmls = jnp.array([float(line.split()[1]) for line in lines[1:]])\n",
    "\n",
    "scores = [is_lmls, bs_lmls, ev_lml_bs_bamojax, smc_fits['lml'], ev_lml_thames]\n",
    "\n",
    "method_names = ['Importance sampling', 'Bridge sampling (Steingroever)', 'Bridge sampling (bamojax)', 'SMC', 'THAMES']\n",
    "\n",
    "jnp.corrcoef_matrix = jnp.corrcoef(jnp.stack(scores))\n",
    "print('Correlation matrix between methods:')\n",
    "print(jnp.corrcoef_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d464a21",
   "metadata": {},
   "source": [
    "All approaches appear in complete agreement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bamojax_numpyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
